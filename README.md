### The Devil is in the Prompts: Retrieval-Augmented Prompt Optimization for Text-to-Video Generation (CVPR25)

[![Paper](https://img.shields.io/badge/Paper-arXiv-red)](https://arxiv.org/pdf/2504.11739) [![Project Page](https://img.shields.io/badge/Project-Website-blue)](https://whynothaha.github.io/Prompt_optimizer/RAPO.html)

##  Abstract

<details><summary>CLICK for the full abstract</summary>


> The evolution of Text-to-video (T2V) generative models, trained on large-scale datasets, has been marked by significant progress. However, the sensitivity of T2V generative models to input prompts highlights the critical role of prompt design in influencing generative outcomes. Prior research has predominantly relied on Large Language Models (LLMs) to align user-provided prompts with the distribution of training prompts, albeit without tailored guidance encompassing prompt vocabulary and sentence structure nuances. To this end, we introduce RAPO, a novel Retrieval-
Augmented Prompt Optimization framework. In order to address potential inaccuracies and ambiguous details generated by LLM-generated prompts. RAPO refines the naive prompts through dual optimization branches, selecting thesuperior prompt for T2V generation. The first branch augments user prompts with diverse modifiers extracted from a learned relational graph, refining them to align with the format of training prompts via a fine-tuned LLM. Conversely, the second branch rewrites the naive prompt using a pre-trained LLM following a well-defined instruction set.
Extensive experiments demonstrate that RAPO can effectively enhance both the static and dynamic dimensions of generated videos, demonstrating the significance of prompt optimization for user-provided prompts.
</details>


## üì• Installation
1. Clone the Repository
```
git clone https://github.com/Vchitect/RAPO.git
cd RAPO
```
2. Set up Environment
```
conda create -n RAPO python=3.10
conda activate RAPO
pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --index-url https://download.pytorch.org/whl/cu118
pip install -r requirements.txt
```

## ü§ó Checkpoint  
Download the required model weights [RAPO](https://huggingface.co/bingjie/RAPO/tree/main), relation graph and pretrained LLM (e.g. , [
Mistral-7B-Instruct-v0.3](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3/tree/main) )and place them in the `ckpt/` and `relation_graph/` directory.
```
ckpt/
‚îÇ‚îÄ‚îÄ all-MiniLM-L6-v2/
‚îÇ‚îÄ‚îÄ Mistral-7B-Instruct-v0.3/
relation_graph/
‚îÇ‚îÄ‚îÄ graph_data/
```


## üñ•Ô∏è Inference  
1. Retrieve related modifiers from relation graph.
```
sh retrieve_modifiers.sh
```
2. Word augmentation and sentence refactoring.
```
sh augment_and_refactor.sh
```
3. Rewrite via instruction.
```
sh rewrite_via_instruction.sh
```





## üìç Citation 

```
@article{gao2025devil,
  title={The Devil is in the Prompts: Retrieval-Augmented Prompt Optimization for Text-to-Video Generation},
  author={Gao, Bingjie and Gao, Xinyu and Wu, Xiaoxue and Zhou, Yujie and Qiao, Yu and Niu, Li and Chen, Xinyuan and Wang, Yaohui},
  journal={arXiv preprint arXiv:2504.11739},
  year={2025}
}
``` 
